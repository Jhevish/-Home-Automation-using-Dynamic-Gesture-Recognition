####Readme for running the project

#To run the main app.py, an arduino,a haptic feedback module, a raspberry pi 5 and its camera are required. COMPULSORY
#Install necessary libraries, tensorflow, mediapipe,matplotlib....
#Open in cmd or other terminals and run directly.



###########To run training models
#INstall necessary libraries: numpy, tensorflow, sklearn.model_selection, matplotlib, keras tuner, os, time
#To run the original github for static gesture file but with some testing, run Originalkeypoint_with analysis_classification_EN.ipynb
#To run the optimized file I coded, run Optimisedkeypoint_classification_EN.ipynb
#To run LSTM model for dynamic gesture recognition, run LSTM_point_history_classification.ipynb
#To run FFNN model for dynamic gesture recognition, run FFNN_point_history_classification.ipynb

########### The data can be found in model as pointhistory.csv and keypoint.csv

###########